{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0abc95",
   "metadata": {},
   "source": [
    "# Assignment 3 â€“ Tabular Dataset Preparation\n",
    "\n",
    "This is Assignment 3 for the Introduction to Deep Learning with PyTorch course (www.leaky.ai).  In this assignment you will practice preparing tabular datasets for training a neural network.  You will practice applying normalization and standardization techniques.  You will also use pandas to convert categorical inputs into numerical values.\n",
    "To Get Started\n",
    "\n",
    "1.\tOpen up a web browser (preferable Chrome)\n",
    "2.\tCopy the Project GitHub Link: https://github.com/LeakyAI/PyTorch-Overview\n",
    "3.\tHead over to Google Colab (https://colab.research.google.com)\n",
    "4.\tLoad the notebook: Tabular Dataset Preparation - Start Here.ipynb\n",
    "5.\tReplace the [TBD]'s with your own code\n",
    "6.\tExecute the notebook after completing each cell and check your answers using the solution notebook\n",
    "\n",
    "Good Luck!\n",
    "\n",
    "Key Takeaways:\n",
    "- You calculated the minimum and maximum values for each input and applied normalization\n",
    "- You then applied standardization and compared the results\n",
    "- You replaced categorical inputs with numerical values using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588ff42",
   "metadata": {},
   "source": [
    "## Part 1 - Standardization and Min Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70bb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch and set the seed for reproducible results\n",
    "import torch\n",
    "torch.set_printoptions(precision=3,sci_mode=False)  # Tensor easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce65faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch tensor with the following content:\n",
    "#    [[1,100,3,0.01,5000],[0,10,8,-0.002,0.01],[1,25,13,0.04,0.2],[1,45,18,-0.05,0.5]]\n",
    "data = torch.tensor([TBD], dtype=torch.float)\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f536545",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "<pre>\n",
    "tensor([[     1.000,    100.000,      3.000,      0.010,   5000.000],\n",
    "        [     0.000,     10.000,      8.000,     -0.002,      0.010],\n",
    "        [     1.000,     25.000,     13.000,      0.040,      0.200],\n",
    "        [     1.000,     45.000,     18.000,     -0.050,      0.500]])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f47071",
   "metadata": {},
   "source": [
    "# Normalize the Values\n",
    "Here you will apply normalization to the column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum value for each column\n",
    "# Hint:  Make sure you use axis = 0 when calling min and max as we\n",
    "#        want to apply the function calls to the columns (not entire tensor)\n",
    "maximums = [TBD]\n",
    "minimums = [TBD]\n",
    "print (f\"Max Values: {maximums.values}\")\n",
    "print (f\"Min Values: {minimums.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75260061",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "<pre>\n",
    "Max Values: tensor([    1.000,   100.000,    18.000,     0.040,  5000.000])\n",
    "Min Values: tensor([     0.000,     10.000,      3.000,     -0.050,      0.010])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying normalization to each input\n",
    "# Use the formula x = (x-min)/(max-min)\n",
    "# Hint:  use maximum.values and minimum.values\n",
    "dataNormalized = (data - [TBD]) / ([TBD] - [TBD])\n",
    "print (dataNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a919cd",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "<pre>\n",
    "tensor([[    1.000,     1.000,     0.000,     0.667,     1.000],\n",
    "        [    0.000,     0.000,     0.333,     0.533,     0.000],\n",
    "        [    1.000,     0.167,     0.667,     1.000,     0.000],\n",
    "        [    1.000,     0.389,     1.000,     0.000,     0.000]])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7adaf6a",
   "metadata": {},
   "source": [
    "### Question\n",
    "What obervations can be made about using normalization?  Does normalization work well in all cases?  How about the last column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3737e",
   "metadata": {},
   "source": [
    "### Your Answer\n",
    "[TBD]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7d168",
   "metadata": {},
   "source": [
    "## Standardize the Values\n",
    "Use the following formula:\n",
    "xStandardized = (x - xMean) / xStdDeviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of each column\n",
    "dataMean = [TBD]\n",
    "dataStDev = [TBD]\n",
    "\n",
    "print (f\"Mean  : {dataMean}\")\n",
    "print (f\"St Dev: {dataStDev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce4f7f",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "<pre>\n",
    "Mean  : tensor([     0.750,     45.000,     10.500,     -0.001,   1250.177])\n",
    "St Dev: tensor([    0.500,    39.370,     6.455,     0.037,  2499.882])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standadize the columns using the following formula:\n",
    "# dataStandardized = (data - mean) / (standardDeviation)\n",
    "# hint - make sure you use axis=0 as we want these operations\n",
    "#        conducted on the columns (not rows, not entire tensor)\n",
    "dataStandardized = (data - [TBD]) / ([TBD])\n",
    "print (dataStandardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fb135",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "<pre>\n",
    "tensor([[ 0.500,  1.397, -1.162,  0.281,  1.500],\n",
    "        [-1.500, -0.889, -0.387, -0.040, -0.500],\n",
    "        [ 0.500, -0.508,  0.387,  1.082, -0.500],\n",
    "        [ 0.500,  0.000,  1.162, -1.322, -0.500]])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9969dd7",
   "metadata": {},
   "source": [
    "### Question\n",
    "What obervations can be made about using normalization?  Does normalization work well in all cases?  How about the last column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52ad0c",
   "metadata": {},
   "source": [
    "### Your Answer\n",
    "[TBD]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc2e53",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "Most tabular datasets contain categorical data.  You will need to convert this type of data into numerical data before training.  We will be using the panda library to automatically convert our the categorical data into numeric using the get_dummies function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a categorical dataset using Pandas\n",
    "import pandas as pd\n",
    "!wget https://raw.githubusercontent.com/LeakyAI/PyTorch-Overview/main/cat_data_v1.csv\n",
    "df = pd.read_csv('cat_data_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the shape of the data by displaying the value of shape\n",
    "[TBD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first portion of the data using head()\n",
    "[TBD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the describe() function to better understand the data\n",
    "# and look for missing values\n",
    "[TBD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66069c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that contain missing values using dropna()\n",
    "[TBD]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce02086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoded values for each column using\n",
    "# the the get_dummies function:\n",
    "OneHot = [TBD]\n",
    "OneHot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28feda0",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "- You calculated the minimum and maximum values for each input and applied normalization\n",
    "- You then applied standardization and compared the results\n",
    "- You replaced categorical inputs with numerical values using one-hot encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
