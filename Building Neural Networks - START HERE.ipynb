{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Networks with PyTorch\n",
    "Copyright 2021, LEAKY.AI LLC\n",
    "\n",
    "This exercise is intended for students taking our Introduction to Deep Learning with PyTorch course at https://www.leaky.ai. In this exercise, we will build some very simple neural networks using PyTorch and explore their properties.\n",
    "\n",
    "In this assingment you will:\n",
    "- Use Google Colab to define neural networks using PyTorch\n",
    "- Learn how to build build more complex models with hidden layers\n",
    "- Learn how to select the appropriate output activation function\n",
    "- Understand how to estimate the model size\n",
    "- Explore the modelâ€™s weights and bias settings\n",
    "\n",
    "In order to complete this assignment:\n",
    "1.\tCopy the following link: https://github.com/LeakyAI/PyTorch-Overview\n",
    "2.\tHead over to Colab: https://colab.research.google.com/\n",
    "3.\tClick on GitHub and paste in the repo link above\n",
    "4.\tClick the magnify icon on the right side of the link you pasted above\n",
    "5.\tClick on the <b>Building Neural Networks.ipynb</b> notebook to get started\n",
    "\n",
    "Next, replace the <b>[TBD]</b> parts below with your code and execute all the cells.  Most cells will have the correct solution shown below the cell for you to check your results.\n",
    "\n",
    "Don't forget to have your PyTorch Cheatsheet handy.  You can download it below the assingment video.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Import the PyTorch Libraries\n",
    "PyTorch has several libraries we will need to build this project.  The main library is the torch library.  We will also load the torchvision library which contains the pre-trained neural network we will need for our project as well as some transformation libraries that will help us process the image before passing it to our neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch, NN module and NN.functional as F\n",
    "# Print out the PyTorch Version\n",
    "import [TBD]\n",
    "import [TBD] as nn\n",
    "import [TBD] as F\n",
    "\n",
    "print (f\"PyTorch Version: {[TBD]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Result:\n",
    "<pre>PyTorch Version: 1.9.0</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch uses random values in many parts of the code\n",
    "# Setting this value will help us have repeatable results when re-executing cells\n",
    "torch.manual_seed(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Build a Simple Model\n",
    "One way to build a simple model in PyTorch is to extend the nn.Module class.  In that case, you will need to define both the __init__ and forward function.  An example is below:\n",
    "\n",
    "<pre>\n",
    "class MyExampleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5,100)\n",
    "        self.fc2 = nn.Linear(100,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        yHat = F.relu(self.fc2(x))\n",
    "        return yHat    \n",
    "</pre>\n",
    "\n",
    "Lets build a network that has the following properties:\n",
    "\n",
    "- 2 inputs (no activation function)\n",
    "- 1 output (no activation function)\n",
    "\n",
    "Skeleton code has been given to you below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a transformation for each image passed into our network\n",
    "class MySimpleNetwork(nn.Module):\n",
    "    \n",
    "        # Network takes 2 inputs, produces 1 output\n",
    "        def __init__(self):\n",
    "            [TBD]\n",
    "            [TBD]\n",
    "            \n",
    "        def forward(self, x):\n",
    "            [TBD]\n",
    "            return [TBD]\n",
    "    \n",
    "# Create an instance of the model and print out summary\n",
    "net = MySimpleNetwork()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Result:  \n",
    "<pre> MySimpleNetwork(\n",
    "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
    ")</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Inspect the Model\n",
    "\n",
    "### Weights and Bias\n",
    "You can read more about weight initialization in PyTorch here:\n",
    "\n",
    "- https://discuss.pytorch.org/t/how-are-layer-weights-and-biases-initialized-by-default/13073/4\n",
    "- https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the weights and bias (option 1)\n",
    "# You can access the model weights directly with\n",
    "# net.fc1.weight.data and net.fc1.bias.data\n",
    "torch.set_printoptions(precision=10)  # show 10 decimal places\n",
    "print (f\"Weights: {[TBD]} \\nBias: {[TBD]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's record the weight values from your model\n",
    "# Copy the weight values above assinging them to the variables below\n",
    "# weight 1, weight 2 and the bias weight (w3)\n",
    "w1 = [TBD]\n",
    "w2 = [TBD]\n",
    "w3 = [TBD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative way to print your model weights is below\n",
    "for param in net.parameters():\n",
    "  print(param.data)\n",
    "\n",
    "# Make sure they match your vairables\n",
    "print (f\"\\nVariables:\\nw1: {w1}\\nw2: {w2}\\nw3: {w3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Result:  \n",
    "<pre>tensor([[0.1021027565, 0.0761914849]])\n",
    "tensor([0.6884815097])\n",
    "\n",
    "Variables:\n",
    "w1: 0.1021027565\n",
    "w2: 0.0761914849\n",
    "w3: 0.6884815097</pre> Note: your actual weight values may be different, just make sure your variables (w1, w2, w3) match your tensor values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Pass a Value into the Network\n",
    "Since the network has not been trained yet, all the weights will be initialized and the output will be garbage.  However, let's follow the process to ensure the output is correctly calculated given the current weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input tensor by providing a Python list with two values (0.9 and 0.2)\n",
    "# A python list example:  [1,2,3,4]\n",
    "inp = torch.tensor([ [TBD], [TBD] ])\n",
    "\n",
    "# Pass the input into the model and print the output\n",
    "out = net(inp)\n",
    "print (f\"Model output: {out.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Check the Calculations of the Model\n",
    "In order to check the calculations, remember that a single network with two inputs and one output (and no activation function) will compute the output as:\n",
    "\n",
    "<pre>Output = Input1 * Weight1 + Input2 * Weight2 + BiasValue * Weight3</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our inputs\n",
    "input1 = 0.9\n",
    "input2 = 0.2\n",
    "bias = 1\n",
    "\n",
    "# The output should be Input1 * W1 + Input2 * W2 + Bias * W3\n",
    "output = [TBD] + [TBD] + [TBD]\n",
    "print (f\"My calculated output:{output:.4}\")\n",
    "\n",
    "# Actual output\n",
    "print (f\"Model's output: {out.item():.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Result:  \n",
    "<pre>My calculated output:0.7956\n",
    "Model's output: 0.7956</pre>Note: You will have different values but both values should be equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Build a Multi-Layer Model to Predict Teddy Bear Sales (Regression)\n",
    "Here, build a model larger model with:\n",
    "\n",
    "- 1 input\n",
    "- 50 as the first hidden layer\n",
    "- 50 as the second hidden layer\n",
    "- 50 as the third hidden layer\n",
    "- 1 output\n",
    "\n",
    "Use a relu (F.relu) activation function on the result of all hidden layers.  Do not use an activation function on the output as this will be a regression task (predicting the number of teddy bears sold on a given day in the year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a transformation for each image passed into our network\n",
    "class MyComplexNetwork(nn.Module):\n",
    "    \n",
    "        # Network takes 2 inputs, produces 1 output\n",
    "        def __init__(self):\n",
    "            [TBD]\n",
    "            [TBD]\n",
    "            [TBD]\n",
    "            [TBD]\n",
    "            [TBD]\n",
    "        def forward(self, x):\n",
    "            x = [TBD]\n",
    "            x = [TBD]\n",
    "            x = [TBD]\n",
    "            x = [TBD]\n",
    "            return x\n",
    "\n",
    "# Create an instance of the model and print out summary\n",
    "net2 = MyComplexNetwork()\n",
    "net2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Result:  \n",
    "<pre>MySimpleNetwork(\n",
    "  (fc1): Linear(in_features=1, out_features=50, bias=True)\n",
    "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
    "  (fc3): Linear(in_features=50, out_features=50, bias=True)\n",
    "  (fc4): Linear(in_features=50, out_features=1, bias=True)\n",
    ")</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use your Neural Network to Predict Teddy Bear Sales\n",
    "Imagine you are running a business that sells teddy bears.  Here we will use your neural network from above to predict future teddy bear sales using a year's worth of teddy bear sales.  We will first train your network on the dataset and then check how accurate it learned how to predict sales based purely on historical sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - Create a Synthetic Teddy Bear Sales Dataset (1 year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random synthentic sales dataset for Teddy Bear sales over 1 year\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "day = torch.linspace(0, 365, 500)\n",
    "teddyBears = 100*(2*torch.cos(day*4*math.pi/365)+torch.rand(500))+200\n",
    "\n",
    "# Display our Teddy Bear sales data for year 1\n",
    "plt.scatter(day, teddyBears)\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Number of Teddy Bears Sold\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 - Train your Neural Network on the Sales Dataset\n",
    "This section will be new to you and will be covered in the next lesson.  In order to train a neural network, we iterate over the training dataset and monitor the loss function.  The loss should decrease as you continue to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare you input and output data by adding a batch dimension\n",
    "y=torch.unsqueeze(teddyBears,dim=1)\n",
    "x=torch.unsqueeze(day, dim=1)\n",
    "\n",
    "# Setup your training optimizer and specify your loss criteria\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Train for 5000 iterations\n",
    "for idx in range(5000):\n",
    "    pred = net2(x)\n",
    "    loss = criterion(pred, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (idx % 1000 == 0):\n",
    "        print (f\"Loss: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Result:  \n",
    "<pre>Loss: 89596.44\n",
    "Loss: 16424.06\n",
    "Loss: 12383.18\n",
    "Loss: 1023.32\n",
    "Loss: 848.64</pre>Note: Your loss values will likely differ a bit but should decrease with each iteration and end below 1000 as in the example above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9 - Compare your Model Predictions with Actuals\n",
    "Here we should the what your neural network is predicting (red) compared to the actual.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.eval()\n",
    "pred = net2(x)\n",
    "plt.scatter(day, teddyBears)\n",
    "plt.scatter(x.detach().numpy()[:], pred.detach().numpy()[:],color=\"red\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Teddy Bears\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Result:  \n",
    "If your model has been defined correctly and trained properly, you should see the red curve following the blue dots.  Your neural network has now been trained and has learned how to map the given day to the amount of expected teddy bear sales for that day!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10 - Make a Sales Prediction using Trained Network\n",
    "Now that our network has been trained, we can use it to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction for a day in the year (use a decimal number e.g. 3.0, 10.1)\n",
    "day = torch.tensor([ [TBD] ])  # Note:  pass a list with a scalar e.g. [2.0]\n",
    "y_pred = net2(day)\n",
    "print (f\"Predicted Number of Sales: {y_pred.item():.0f} Teddy Bears\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- You built a simple PyTorch neural network\n",
    "- You explored the model details including the weight and bias values\n",
    "- You defined a multi-layer neural network\n",
    "- You trained it on teddy bear sales data and used it to predict sales\n",
    "\n",
    "Congratulations for finishing the first assingment!  \n",
    "\n",
    "Keep it going!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
