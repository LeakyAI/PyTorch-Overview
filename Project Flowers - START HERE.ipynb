{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8L3_hoEaxfO"
   },
   "source": [
    "# Project Flowers - Predicting Types of Flowers (Classification)\n",
    "\n",
    "\n",
    "In this project you will build a flower detector and use transfer learning to train it.  You will be using a real-world dataset which contains 4242 images of flowers across 5 different flower varieties.\n",
    "\n",
    "### In this project you will:\n",
    "- Download and analyze the flower vision dataset\n",
    "- Convert the images into PyTorch dataloaders building both the training, validation and testing sets\n",
    "- Use a state-of-the-art vision model and apply transfer learning to build and train your model\n",
    "- Experiment with different models to achieve a target average loss (or better) on the test set\n",
    "- Analyze your modelâ€™s performance using accuracy, confusion matrix and other techniques\n",
    "- Test your model using your own images of flowers\n",
    "\n",
    "### To get started:\n",
    "- Open up a web browser (preferable Chrome)\n",
    "- Copy the Project GitHub Link: https://github.com/LeakyAI/PyTorch-Overview\n",
    "- Head over to Google Colab (https://colab.research.google.com)\n",
    "- Load the notebook: Project Flowers - START HERE.ipynb\n",
    "- Replace the [TBD]'s with your own code\n",
    "- Execute the notebook after completing each cell\n",
    "\n",
    "### Hint\n",
    "Don't forget to print out and have your PyTorch and Pandas Cheatsheet handy when tackling this project. You can find it on the right-hand side of the the course home landing page in the Resource section.\n",
    "\n",
    "### How to Submit your Project:\n",
    "When you have completed filling out all the TBD sections and achieved a 90% accuracy or better on the test set, you may submit your project for review by downloading the notebook and emailing it to the address listed on the project page inside of your course.\n",
    "\n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmGLC2_waxfW"
   },
   "source": [
    "# Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orf5S7fQaxfX",
    "outputId": "67387293-5a88-4d52-8556-045c95e32085"
   },
   "outputs": [],
   "source": [
    "# Downlod the flower dataset\n",
    "!wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
    "data_dir = \"/content/flower_photos/\" \n",
    "\n",
    "# Unzip all the images    \n",
    "!tar zxvf flower_photos.tgz\n",
    "\n",
    "# Download a state-of-the-art vision model (efficientnet)\n",
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEB55mSLaxfY"
   },
   "source": [
    "# Load the Libraries and Check for GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqZ7vadpaxfY"
   },
   "outputs": [],
   "source": [
    "# Load the appropiate PyTorch libraries and visualization libraries\n",
    "import [TBD]\n",
    "import [TBD].nn as nn\n",
    "import [TBD].optim as optim\n",
    "import [TBD].nn.functional as F\n",
    "from [TBD] import datasets, transforms, models\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zG8yS1hsaxfZ"
   },
   "outputs": [],
   "source": [
    "# Setup our notebook to be able to regenertate results\n",
    "SEED = 4321\n",
    "random.seed([TBD])\n",
    "torch.manual_seed([TBD])\n",
    "torch.cuda.manual_seed([TBD])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed([TBD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNaUxzj0axfZ",
    "outputId": "76cf7462-e0ab-4e80-84f6-2bee18ca9da0"
   },
   "outputs": [],
   "source": [
    "# This project will require a GPU\n",
    "# Check which GPU is avaialble\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Set the device type to cude or cpu depending on what is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Print out the details of the GPU or CPU backend\n",
    "print (\"GPU is availble!\" if use_cuda else \"No GPU :(\")\n",
    "print (torch.cuda.get_device_name(0) if use_cuda else None)\n",
    "print (torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecPjJ2AJaxfa"
   },
   "source": [
    "# Load our Data into Training, Validation and Test Sets\n",
    "Next, we will load our dataset using PyTorch's built-in function (ImageFolder).  We will start by building our image transformations for both training (with data augmentation) as well as testing (no data augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFpLzFXdaxfb"
   },
   "outputs": [],
   "source": [
    "# Normalize our images with the ImageNet means and stdev\n",
    "# The mean values are [0.485, 0.456, 0.406]\n",
    "# The standard deviation values are [0.229, 0.224, 0.225]\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[[TBD], [TBD], [TBD]], \n",
    "    std=[[TBD], [TBD], [TBD]])\n",
    "\n",
    "# Undo our normalization for display purposes\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225])\n",
    "\n",
    "# Build our transform for training using data augmentation \n",
    "trans = transforms.Compose([transforms.RandomRotation(25),\n",
    "                            transforms.RandomResizedCrop(224),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.ToTensor(),\n",
    "                            normalize])\n",
    "\n",
    "# Build our transform for validation and testing dataset\n",
    "# without data augmentation (no data augmentation)\n",
    "transNoAugment = transforms.Compose([transforms.[TBD](224), \n",
    "                                     transforms.[TBD](224),\n",
    "                                     transforms.[TBD](),\n",
    "                                     [TBD]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aciq2TAzaxfc"
   },
   "outputs": [],
   "source": [
    "# Split our dataset into test, train and validation sets \n",
    "# using about 80% of our dataset for training.\n",
    "# Create datasets using ImageFolder which will use \n",
    "# foldernames to populate labels\n",
    "fullDataAug = datasets.ImageFolder(data_dir, transform=[TBD])\n",
    "fullDataNoAug = datasets.ImageFolder(data_dir, transform=[TBD])\n",
    "\n",
    "# Save the class labels for later\n",
    "classes=fullDataAug.classes\n",
    "\n",
    "# Create the index splits for training, validation and test\n",
    "total = len(fullDataAug)\n",
    "indices = list(range(total))\n",
    "\n",
    "# Grab 80% of the data for training, then 10% / 10% for test and validation\n",
    "trainingPercent = .8\n",
    "split1 = int(total*trainingPercent)\n",
    "split2 = int(((total - split1)/2)+split1)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Build datasets by using Subset and pass the split indices\n",
    "traindata = Subset(fullDataAug, indices[:split1])\n",
    "valdata = Subset(fullDataNoAug, indices[split1:split2])\n",
    "testdata = Subset(fullDataNoAug, indices[split2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzTamjycaxfc"
   },
   "source": [
    "# Analyze our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ATKr6Zvaxfc",
    "outputId": "f7b72eb6-49e1-4168-9442-7b7975fac33c"
   },
   "outputs": [],
   "source": [
    "# Print out the classes and association found by ImageFolder using\n",
    "# the class_to_idx variable in the dataset class\n",
    "print(fullDataAug.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yz9__nufaxfd",
    "outputId": "f1a2db89-8805-4cc4-d473-a26d070b2bee"
   },
   "outputs": [],
   "source": [
    "# Analyze the dataset by checking the balance of the labels\n",
    "@torch.no_grad() \n",
    "def labelDistribution(dataset, classes, setName):\n",
    "    num_classes = len(classes)\n",
    "    labels = torch.zeros(num_classes, dtype=torch.long)\n",
    "    for _, target in dataset:\n",
    "        labels[target] += 1\n",
    "    print ('------- {} ({}) ------- '.format(setName,labels.sum()))\n",
    "    for idx, name in enumerate(classes):\n",
    "        print ('{} {} ({:0.1f}%)'.format(labels[idx], name, labels[idx].float()/labels.sum()*100))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Check our Training Dataset\n",
    "labelDistribution([TBD], classes, \"Train\")\n",
    "\n",
    "# Check our Validation Dataset\n",
    "labelDistribution([TBD], classes, \"Validation\")\n",
    "\n",
    "# Check our Test Dataset\n",
    "labelDistribution([TBD], classes, \"Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBSjZhQgaxfd"
   },
   "source": [
    "# Compare Original vs. Augmented Images\n",
    "Here we will take a closer look at how the images are modified by the transform.  You can replay this and see the changes made to the image.  Note, both images have been normalized to the ImageNet mean/stdev so their colors are modified a bit from the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "d9KecwbKaxfd",
    "outputId": "028f1eda-b5a3-4a2f-d6be-3218ae457938"
   },
   "outputs": [],
   "source": [
    "def compareImg2Img(img1,img2):\n",
    "    fontsz = 16\n",
    "    img1 = inv_normalize(img1)\n",
    "    img2 = inv_normalize(img2)\n",
    "    \n",
    "    img1 = img1.numpy()\n",
    "    img1 = np.transpose(img1, (1, 2, 0))\n",
    "    img2 = img2.numpy()\n",
    "    img2 = np.transpose(img2, (1, 2, 0))\n",
    "\n",
    "    f, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "    ax[0].imshow(img1, cmap='gray')\n",
    "    ax[1].imshow(img2,cmap='gray')\n",
    "    ax[0].set_title('No Augmentation', fontsize=fontsz)\n",
    "    ax[1].set_title('Augmented', fontsize=fontsz)\n",
    "\n",
    "compareImg2Img(fullDataNoAug[traindata.indices[10]][0],traindata[10][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbsUB-Jsaxfd"
   },
   "source": [
    "# Create the DataLoaders for Train, Validation and Test\n",
    "Using the 3 datasets above, create our dataloaders for each making sure to pass in the num_workers and batch_size.  Shufflying the data is a good idea for the training dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84HLN5i4axfe"
   },
   "outputs": [],
   "source": [
    "num_workers = 2\n",
    "batch_size = 32\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader([TBD], batch_size=[TBD], \n",
    "                                          num_workers=num_workers, \n",
    "                                          drop_last=True, shuffle=[TBD])\n",
    "\n",
    "valLoader = torch.utils.data.DataLoader([TBD], batch_size=[TBD],\n",
    "                                        num_workers=num_workers, \n",
    "                                        drop_last=True)\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader([TBD], batch_size=[TBD], \n",
    "                                         num_workers=num_workers, \n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEyh135paxfe",
    "outputId": "e0a64b3c-703d-45d2-dbf2-13283089ca36"
   },
   "outputs": [],
   "source": [
    "# Check out the first batch of labels and ensure they are shuffled\n",
    "\n",
    "# Grab the first batch of inputs (x) and outputs (y)\n",
    "x,y = next(iter(trainLoader))\n",
    "\n",
    "# Print out the labels and ensure they are randomized\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNfzHQhhaxfe"
   },
   "source": [
    "# Build the Scoring and Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEQPOwTyaxff"
   },
   "outputs": [],
   "source": [
    "# Calculate validation loss and accuracy for a loader and model\n",
    "# Return the average loss\n",
    "@torch.no_grad() \n",
    "def scoreModel(loader, criterion, model, device, name):\n",
    "    \n",
    "    # Set the model to eval (not training)\n",
    "    model.[TBD]()        \n",
    "    lossTotal = 0.0\n",
    "    numCorrect = 0\n",
    "\n",
    "    for x,y in loader:\n",
    "        \n",
    "        # Move the input x, label y to the appropiate device found in the \"Check for GPU Support\" above\n",
    "        x, y = x.to([TBD]), y.to([TBD])\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        lossTotal+=loss.item()*x.size(0)\n",
    "        \n",
    "        predClass = pred.max(1)[1] # grab largest logit index of the 5 converting [32,5] to [32]\n",
    "        numCorrect+=((predClass==y).sum())\n",
    "\n",
    "    lossAvg = lossTotal/len(loader.sampler)\n",
    "    acc = numCorrect.float()/len(loader.sampler)*100\n",
    "    \n",
    "    print('{} Loss {:0.2f}  Accuracy: {:0.2f}%  '.format(name,lossAvg,acc),end='')\n",
    "    \n",
    "    return lossAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWOga5a8axff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train our model - train and save the best model in fileName\n",
    "def trainModel(model, trainLoader, criterion, optimizer, fileName, epochs = 5):\n",
    "\n",
    "    # Time how long the model was trained\n",
    "    tStart = time.time()\n",
    "\n",
    "    # Initialize the validation loss to inf\n",
    "    v_loss = float('inf')  \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        t_loss = 0  \n",
    "\n",
    "        # Set the model to train\n",
    "        model.[TBD]()\n",
    "\n",
    "        # Iterate across the training dataloader\n",
    "        for x, y in [TBD]:\n",
    "            x, y = x.to([TBD]), y.to([TBD])  # Move x and y to proper device\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Hint: loss.item() represents the average loss for the current batch\n",
    "            t_loss += loss.item()*x.size(0)  # Multiply by the current batch size\n",
    "\n",
    "        # Compute the final training loss after a full epoch\n",
    "        finalLoss = t_loss / len(trainLoader.sampler)\n",
    "        print ('{} / {} Training Loss {:0.2f}  '.format(epoch+1,epochs,finalLoss), end='')\n",
    "\n",
    "        # Check the validation loss and save the model only if its decreased\n",
    "        loss = scoreModel(valLoader, criterion, model, device, \"Validation\")\n",
    "        if (v_loss>loss):\n",
    "            torch.save(model.state_dict(), fileName)\n",
    "            print (\"  Saving model...\", end='')\n",
    "            v_loss = loss\n",
    "        print (\"\\n\")\n",
    "    print (\"Total Training Time: {:0.2f} seconds\".format(time.time()-tStart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynJndd_raxff"
   },
   "source": [
    "# Build a Model with 5 Classes using a Pre-Trained Model (ResNet 50)\n",
    "Here we will use ResNet50 with pre-trained weights and replace the last layer with a new classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVP8c2j3axfg"
   },
   "outputs": [],
   "source": [
    "# Start by loading the Resnet50 model with pre-trained weights\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Freeze the model weights keeping only FC trainable\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Build new FC layer\n",
    "from collections import OrderedDict\n",
    "model.fc = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.[TBD](2048, 500)),\n",
    "                          ('relu', nn.[TBD]()),\n",
    "                          ('dropout', nn.[TBD](0.25)),\n",
    "                          ('fc2', nn.Linear(500, [TBD])),\n",
    "                          ]))\n",
    "\n",
    "# Push model to GPU if we have one\n",
    "model = model.to([TBD])\n",
    "\n",
    "# Define our loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=[TBD], momentum=[TBD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzaIw9gyaxfg",
    "outputId": "284c9294-7b87-4331-c933-38bfdaa0c0c7"
   },
   "outputs": [],
   "source": [
    "trainModel(model, trainLoader, criterion, optimizer, \"bestflowerresnet.pt\")\n",
    "model.load_state_dict(torch.load(\"bestflowerresnet.pt\"))\n",
    "scoreModel(testLoader, criterion, model, device, \"Testing\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLZl0UIxaxfg"
   },
   "source": [
    "# Build a Model with 5 Classes using a Pre-Trained Model (EfficientNet-B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dffPVbWWaxfg"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=[TBD])\n",
    "model = model.to([TBD])\n",
    "\n",
    "# Define our loss and optimizer and then fine tune\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=[TBD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpgRMpN6axfh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainModel(model, trainLoader, criterion, optimizer, \"bestflowerenet.pt\")\n",
    "model.load_state_dict(torch.load(\"bestflowerenet.pt\"))\n",
    "scoreModel(testLoader, criterion, model, device, \"Testing\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy58cKppaxfh"
   },
   "source": [
    "# Analyze the Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eonD5VuVaxfh"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "%matplotlib inline  \n",
    "import sklearn\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "@torch.no_grad()\n",
    "def confusion(loader, model):\n",
    "    preds = torch.tensor([], dtype=torch.float, device=device)\n",
    "    labels = torch.tensor([],dtype=torch.long, device=device)\n",
    "    model.eval()\n",
    "    for x,y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "        preds = torch.cat((preds, pred), dim=0)\n",
    "        labels = torch.cat((labels,y), dim=0)\n",
    "\n",
    "    preds = preds.argmax(dim=1)\n",
    "    cm = confusion_matrix(labels.cpu(), preds.cpu())\n",
    "\n",
    "    # Visualize the confusion matrix using SciKit learn code\n",
    "    normalize=False\n",
    "    title='Confusion matrix'\n",
    "    cmap=plt.cm.Blues\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix for the model using the test data\n",
    "preds, labels = confusion(testLoader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlQFKWNFaxfi"
   },
   "source": [
    "# Congratulations on Finishing the Project!\n",
    "### In this project you:\n",
    "- Downloaded and analyzed the flower vision dataset\n",
    "- Converted the images into PyTorch dataloaders building both the training, validation and testing sets\n",
    "- Used a state-of-the-art vision model and apply transfer learning to build and train your model\n",
    "- Experimented with different models to achieve a target average loss (or better) on the test set\n",
    "- Analyzed your modelâ€™s performance using accuracy, confusion matrix and other techniques\n",
    "- Tested your model using your own images of flowers\n",
    "\n",
    "### How to Submit your Project:\n",
    "When you have completed filling out all the TBD sections and achieved a 90% accuracy or better on the test set, you may submit your project for review by downloading the notebook and emailing it to the address listed on the project page inside of your course."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project Flowers - Solution (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
