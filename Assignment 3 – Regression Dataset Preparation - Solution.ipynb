{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e7979e",
   "metadata": {},
   "source": [
    "# Assignment 3 – Regression Dataset Preparation\n",
    "\n",
    "This is Assignment 3 for the Introduction to Deep Learning with PyTorch course (www.leaky.ai).  \n",
    "\n",
    "In this assignment you will practice preparing a real-world dataset for training a neural network.  You will be dealing with missing items, variable ranges in the input data as well as categorical text features.\n",
    "\n",
    "Finally, when training neural networks, instead of processing one input at a time, it’s usually better to process a batch of inputs at the same time.  This leads to better training results and enables us to take advantage of parallel computing to accelerate the calculations.  But how do we create batches of input data?  The good news that PyTorch includes a dataset and dataloader object that automatically creates batches of the input data for the training process.  Once the dataset is ready, all we have to do is wrap it into a dataset object and pass that to our dataloader object.   You will practice this technique towards the end of the assignment.\n",
    "\n",
    "### To Get Started\n",
    "1.\tOpen up a web browser (preferable Chrome)\n",
    "2.\tCopy the Project GitHub Link: https://github.com/LeakyAI/PyTorch-Overview\n",
    "3.\tHead over to Google Colab (https://colab.research.google.com)\n",
    "4.\tLoad the notebook: <b>Assignment 3 – Regression Dataset Preparation - Start Here.ipynb</b>\n",
    "5.\tReplace the [TBD]'s with your own code\n",
    "6.\tExecute the notebook after completing each cell and check your answers using the solution notebook\n",
    "\n",
    "Good Luck!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174d57ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10.],\n",
      "        [11., 12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19., 20.]])\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch and check the version\n",
    "# Create a PyTorch tensor with the following content\n",
    "# Tensor a should contain [[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15],[16,17,18,19,20]]\n",
    "import torch\n",
    "torch.manual_seed(6)\n",
    "torch.__version__\n",
    "a = torch.tensor([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15],[16,17,18,19,20]], dtype=torch.float)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88237509",
   "metadata": {},
   "source": [
    "# Finding Maximum Values\n",
    "Here you will explore different approachs to extract the highest values from tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c4398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 20.0\n",
      "Min: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Find the highest and lowest value in the entire tensor \n",
    "maximum = a.max()\n",
    "minimum = a.min()\n",
    "\n",
    "print (f\"Max: {maximum.item()}\\nMin: {minimum.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260baaf1",
   "metadata": {},
   "source": [
    "### Correct Answer:  \n",
    "<pre>\n",
    "Values:\n",
    "tensor([[ 5.,  4.],\n",
    "        [10.,  9.],\n",
    "        [15., 14.],\n",
    "        [20., 19.]])\n",
    "\n",
    "Indicies:\n",
    "tensor([[4, 3],\n",
    "        [4, 3],\n",
    "        [4, 3],\n",
    "        [4, 3]])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642bf49",
   "metadata": {},
   "source": [
    "# Standardize Columns\n",
    "For tabular datasets, you will likely need to standardize or normalize the data before using it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6d83b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10.],\n",
      "        [11., 12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19., 20.]])\n",
      "\n",
      "Means:\n",
      "tensor([ 8.5000,  9.5000, 10.5000, 11.5000, 12.5000])\n",
      "\n",
      "Standard Deviations:\n",
      "tensor([6.4550, 6.4550, 6.4550, 6.4550, 6.4550])\n",
      "\n",
      "Standardized:\n",
      "tensor([[-1.1619, -1.1619, -1.1619, -1.1619, -1.1619],\n",
      "        [-0.3873, -0.3873, -0.3873, -0.3873, -0.3873],\n",
      "        [ 0.3873,  0.3873,  0.3873,  0.3873,  0.3873],\n",
      "        [ 1.1619,  1.1619,  1.1619,  1.1619,  1.1619]])\n"
     ]
    }
   ],
   "source": [
    "# Standardize the column values\n",
    "\n",
    "# Start by calculating the mean for each column (dim=0)\n",
    "mean = a.mean(dim=0)\n",
    "\n",
    "# Then, calculate the standard deviation for each column (dim=0)\n",
    "std = a.std(dim=0)\n",
    "\n",
    "# Standardize the data by subtracting the mean and dividing by st. dev.\n",
    "a_std = (a - mean) / std\n",
    "\n",
    "# Output the results\n",
    "print (a)\n",
    "print (f\"\\nMeans:\\n{mean}\")\n",
    "print (f\"\\nStandard Deviations:\\n{std}\")\n",
    "print (f\"\\nStandardized:\\n{a_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77339f8a",
   "metadata": {},
   "source": [
    "### Correct Answer:  \n",
    "<pre>\n",
    "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
    "        [ 6.,  7.,  8.,  9., 10.],\n",
    "        [11., 12., 13., 14., 15.],\n",
    "        [16., 17., 18., 19., 20.]])\n",
    "\n",
    "Means:\n",
    "tensor([[ 8.5000,  9.5000, 10.5000, 11.5000, 12.5000]])\n",
    "\n",
    "Standard Deviations:\n",
    "tensor([[6.4550, 6.4550, 6.4550, 6.4550, 6.4550]])\n",
    "\n",
    "Standardized:\n",
    "tensor([[-1.1619, -1.1619, -1.1619, -1.1619, -1.1619],\n",
    "        [-0.3873, -0.3873, -0.3873, -0.3873, -0.3873],\n",
    "        [ 0.3873,  0.3873,  0.3873,  0.3873,  0.3873],\n",
    "        [ 1.1619,  1.1619,  1.1619,  1.1619,  1.1619]])</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd16f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4179087f",
   "metadata": {},
   "source": [
    "## Key Takeaways:\n",
    "- You removed missing items from the dataset\n",
    "- You used standardization to ensure your input values were of similar scale\n",
    "- You replaced categorical inputs with numerical values using one-hot encoding\n",
    "- You wrapped the dataset using the PyTorch dataset and dataloader object making it ready to be used for training a neural network\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
