{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d78967",
   "metadata": {},
   "source": [
    "# Assignment 3 – Regression Dataset Preparation\n",
    "\n",
    "This is Assignment 3 for the Introduction to Deep Learning with PyTorch course (www.leaky.ai).  \n",
    "\n",
    "In this assignment you will practice preparing a real-world dataset for training a neural network.  You will be dealing with missing items, variable ranges in the input data as well as categorical text features.\n",
    "\n",
    "Finally, when training neural networks, instead of processing one input at a time, it’s usually better to process a batch of inputs at the same time.  This leads to better training results and enables us to take advantage of parallel computing to accelerate the calculations.  But how do we create batches of input data?  The good news that PyTorch includes a dataset and dataloader object that automatically creates batches of the input data for the training process.  Once the dataset is ready, all we have to do is wrap it into a dataset object and pass that to our dataloader object.   You will practice this technique towards the end of the assignment.\n",
    "\n",
    "### To Get Started\n",
    "1.\tOpen up a web browser (preferable Chrome)\n",
    "2.\tCopy the Project GitHub Link: https://github.com/LeakyAI/PyTorch-Overview\n",
    "3.\tHead over to Google Colab (https://colab.research.google.com)\n",
    "4.\tLoad the notebook: <b>Assignment 3 – Regression Dataset Preparation - Start Here.ipynb</b>\n",
    "5.\tReplace the [TBD]'s with your own code\n",
    "6.\tExecute the notebook after completing each cell and check your answers using the solution notebook\n",
    "\n",
    "Good Luck!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688191f",
   "metadata": {},
   "source": [
    "## Part 1 - Standardization and Min Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e11c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x171a195f510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import PyTorch and set the seed for reproducible results\n",
    "import torch\n",
    "torch.manual_seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f37597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     1.000,    100.000,      3.000,      0.010,   5000.000],\n",
      "        [     0.000,     10.000,      8.000,     -0.002,      0.010],\n",
      "        [     1.000,     25.000,     13.000,      0.040,      0.200],\n",
      "        [     1.000,     45.000,     18.000,     -0.050,      0.500]])\n"
     ]
    }
   ],
   "source": [
    "# Create a PyTorch tensor with the following content\n",
    "# [[1,100,3,0.01,5000],[0,10,8,-0.002,0.01],[1,25,13,0.04,0.2],[1,45,18,-0.05,0.5]]\n",
    "a = torch.tensor([[1,100,3,0.01,5000],[0,10,8,-0.002,0.01],[1,25,13,0.04,0.2],[1,45,18,-0.05,0.5]], dtype=torch.float)\n",
    "torch.set_printoptions(precision=3,sci_mode=False)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713f3e49",
   "metadata": {},
   "source": [
    "# Normalize the Values\n",
    "Here you will apply Max Min Normalization to the column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd9e8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1.000,   100.000,    18.000,     0.040,  5000.000])\n"
     ]
    }
   ],
   "source": [
    "# find the max\n",
    "maximums = a.max(axis=0)\n",
    "print (maximums.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71929285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0.000,     10.000,      3.000,     -0.050,      0.010])\n"
     ]
    }
   ],
   "source": [
    "# find the minimums\n",
    "minimums = a.min(axis=0)\n",
    "print (minimums.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f99c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1.000,     1.000,     0.000,     0.667,     1.000],\n",
      "        [    0.000,     0.000,     0.333,     0.533,     0.000],\n",
      "        [    1.000,     0.167,     0.667,     1.000,     0.000],\n",
      "        [    1.000,     0.389,     1.000,     0.000,     0.000]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize A\n",
    "aNormalized = (a - minimums.values) / (maximums.values - minimums.values)\n",
    "print (aNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1118c",
   "metadata": {},
   "source": [
    "## Standardize the Values\n",
    "Use the following formula:\n",
    "xStandardized = (x - xMean) / xStdDeviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "401d6e2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14836/437612467.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mxMean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#printf (\"Mean: {xMean}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of each column\n",
    "xMean = a.mean(axis = 0)\n",
    "#printf (\"Mean: {xMean}\")\n",
    "python.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
